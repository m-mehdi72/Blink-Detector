{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mediapipe import solutions\n",
    "import cvzone\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "from cvzone.PlotModule import LivePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "detector = FaceMeshDetector(maxFaces=1)\n",
    "plotY = LivePlot(640, 640, [20, 50], invert=True)\n",
    "\n",
    "idListL = [22, 23, 24, 26, 110, 157, 158, 159, 160, 161, 130, 243]\n",
    "ratioList = []\n",
    "blinkCounter = 0\n",
    "counter = 0\n",
    "color = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idListR = [ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_distance(frame):\n",
    "    # Convert frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    results = face_detection.process(frame_rgb)\n",
    "    \n",
    "\n",
    "    # Check if faces are detected\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, ic = frame.shape\n",
    "            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                    int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "            cv2.rectangle(frame, bbox, (255, 0, 255), 2)\n",
    "\n",
    "            # Calculate area of bounding box\n",
    "            bbox_area = bboxC.width * bboxC.height\n",
    "\n",
    "            # Define threshold for face distance\n",
    "            distance_threshold = 0.2  # Adjust as needed\n",
    "\n",
    "            # Check if face is too far or too close\n",
    "            if bbox_area < distance_threshold:\n",
    "                cv2.putText(frame, \"Please come closer\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                return 0, frame\n",
    "            else:\n",
    "                cv2.putText(frame, \"Face detected\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                return 1, frame\n",
    "\n",
    "    else:\n",
    "        # If no face detected, prompt user to come closer\n",
    "        cv2.putText(frame, \"No face detected. Please come closer\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        return 0, frame\n",
    "    \n",
    "while True:\n",
    "\n",
    "    success, img = cap.read()\n",
    "\n",
    "    mp_face_detection = solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "    distance, img = check_distance(img)\n",
    "    if distance == 0:\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(25)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "    img, faces = detector.findFaceMesh(img, draw=True)\n",
    "\n",
    "    if faces:\n",
    "        face = faces[0]\n",
    "        for id in idListL:\n",
    "            cv2.circle(img, face[id], 2,color, cv2.FILLED)\n",
    "\n",
    "        leftUp = face[159]\n",
    "        leftDown = face[23]\n",
    "        leftLeft = face[130]\n",
    "        leftRight = face[243]\n",
    "        lenghtVer, _ = detector.findDistance(leftUp, leftDown)\n",
    "        lenghtHor, _ = detector.findDistance(leftLeft, leftRight)\n",
    "\n",
    "        cv2.line(img, leftUp, leftDown, (0, 200, 0), 2)\n",
    "        cv2.line(img, leftLeft, leftRight, (0, 200, 0), 2)\n",
    "\n",
    "        ratio = int((lenghtVer / lenghtHor) * 100)\n",
    "        ratioList.append(ratio)\n",
    "        if len(ratioList) > 3:\n",
    "            ratioList.pop(0)\n",
    "        ratioAvg = sum(ratioList) / len(ratioList)\n",
    "\n",
    "        if ratioAvg < 25 and counter == 0:\n",
    "            blinkCounter += 1\n",
    "            color = (0,200,0)\n",
    "            counter = 1\n",
    "        if counter != 0:\n",
    "            counter += 1\n",
    "            if counter > 10:\n",
    "                counter = 0\n",
    "                color = (255,0, 255)\n",
    "\n",
    "        cvzone.putTextRect(img, f'Blink Count: {blinkCounter}', (50, 100),\n",
    "                        colorR=color)\n",
    "\n",
    "        imgPlot = plotY.update(ratioAvg, color)\n",
    "        img = cv2.resize(img, (640, 640))\n",
    "        imgStack = cvzone.stackImages([img, imgPlot], 2, 1)\n",
    "    else:\n",
    "        img = cvzone.stackImages([img, img], 2, 1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    # cv2.waitKey(25)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
